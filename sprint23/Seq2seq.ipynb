{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seqとは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡単に言うと、語句の並びを入力して、別の語句の並びに変換する際のルールを学習する手法のことを言います。  \n",
    "例えば、機械翻訳に応用すると、日本語を英語に翻訳したり、英語を日本語に翻訳したりすることが可能になります。  \n",
    "Google翻訳もこのSeq2seqを使っています。  \n",
    "他には対話型ロボットやチャットボット、メールの自動返信などにもSeq2seqが使われています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習では、「語句の並び」は数値（ベクトル）に変換されるため、これを応用し、語句の並びの代わりに画像を入力して、  \n",
    "語句の並びを出力する（画像の説明を作成する）というルールも学習できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2seqは**Encoder**と**Decoder**に分かれており、  \n",
    "Encoderで入力データをエンコード（データの変換）し、Decoderでエンコードしたデータをエンコードされる前のデータに戻すということを行います。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械翻訳で言うと、日本語の入力をベクトルの数値データにエンコード（変換）し、特徴を抽出します。  \n",
    "その後、そのエンコードされたデータをベクトルから言語にデコードすれば、その出力が英語になっていたりするわけです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        \n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "        \n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "    \n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "        \n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dhs)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm.Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm.Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm.b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm.Wx, lstm.Wh, lstm.b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "        \n",
    "        self.params, self.grads = [], []\n",
    "        \n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h)\n",
    "        \n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "    \n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "    \n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sampled_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "        \n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "            \n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "            \n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "        \n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "        \n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "        \n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "    \n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generate(h, stard_id, sample_size)\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
